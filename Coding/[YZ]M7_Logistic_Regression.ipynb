{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1QOqgaUsZzJNqfHayiur8eqVpwk6kZh60","timestamp":1665943122075}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"l0phSUcqjMs4"},"source":["A few key concepts that we will revisit in this walk-through are:\n","\n","1. Apply String Indexer method to find the index of the categorical columns\n","\n","2. Apply OneHot encoding for the categorical columns\n","\n","3. Apply String indexer for the output variable “label” column\n","\n","4. VectorAssembler is applied for both categorical columns and numeric columns. VectorAssembler is a transformer that combines a given list of columns into a single vector column."]},{"cell_type":"markdown","metadata":{"id":"vTrb_YsFDVsT"},"source":["**Step 1**: Install Spark"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yTbkAxL5p1g7","executionInfo":{"status":"ok","timestamp":1679059324821,"user_tz":420,"elapsed":76206,"user":{"displayName":"Yu Zhang","userId":"15502925183467796581"}},"outputId":"8e7d0186-d067-413b-8090-df3f820bde88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# innstall java\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","# install spark (change the version number if needed)\n","!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n","\n","# unzip the spark file to the current folder\n","!tar xf spark-3.0.0-bin-hadoop3.2.tgz"],"metadata":{"id":"2qY9HjthtVDs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""],"metadata":{"id":"J0rkjegDtvZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# install findspark using pip\n","!pip install -q findspark"],"metadata":{"id":"Dmv0qW7YuKuH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install pyspark==3.0.2"],"metadata":{"id":"OfQbZI1U6gSA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679059367289,"user_tz":420,"elapsed":36814,"user":{"displayName":"Yu Zhang","userId":"15502925183467796581"}},"outputId":"c1198da1-6f34-438d-f02d-414e4aad566b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark==3.0.2\n","  Downloading pyspark-3.0.2.tar.gz (204.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/204.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting py4j==0.10.9\n","  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.0.2-py2.py3-none-any.whl size=205186690 sha256=e8f867eb87d036e2242501259b68a8bc1fff02130b9dcf71d300f92da095dcea\n","  Stored in directory: /root/.cache/pip/wheels/aa/8e/b9/ed8017fb2997a648f5868a4b728881f320e3d1bd2b0274f137\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.0.2\n"]}]},{"cell_type":"code","metadata":{"id":"75i_k4uceE1b"},"source":["import findspark\n","findspark.init()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import SparkSession\n","from pyspark.sql import SparkSession\n","# Create a Spark Session\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n","# Check Spark Session Information\n","spark\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"Ji03JSROuVcB","executionInfo":{"status":"ok","timestamp":1679059379660,"user_tz":420,"elapsed":12385,"user":{"displayName":"Yu Zhang","userId":"15502925183467796581"}},"outputId":"d631c7be-014e-41bd-807d-0fa8ae753754"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7fd7143173d0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://29ff834d5963:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.0.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>pyspark-shell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"dDgFu5_9eWQp"},"source":["# Create spark_session\n","spark_session = SparkSession.builder.getOrCreate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T2GIH4gDebm-"},"source":["sc = spark_session.sparkContext"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aoD2D6UKDwfT"},"source":["**Step 2**: Insert SQLContext wrapper around the Spark Context"]},{"cell_type":"code","metadata":{"id":"S2fY4t17dtkI"},"source":["from pyspark.sql import SQLContext\n","url = \"https://raw.githubusercontent.com/guru99-edu/R-Programming/master/adult_data.csv\"\n","from pyspark import SparkFiles\n","sc.addFile(url)\n","sqlContext = SQLContext(sc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NMwK3HlIEB-S"},"source":["**Step 3**: Read the contents from the 'adults.csv' file"]},{"cell_type":"code","metadata":{"id":"K5QyIgsFekRW"},"source":["df = sqlContext.read.csv(SparkFiles.get(\"adult_data.csv\"), header=True, inferSchema= True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iie5xwGwENTq"},"source":["**Step 4**: Examine the schema of the underlying dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0tNkToGfBKs","outputId":"284bf466-fcf4-4af3-946c-597b8fd4145e","executionInfo":{"status":"ok","timestamp":1679059398108,"user_tz":420,"elapsed":10,"user":{"displayName":"Yu Zhang","userId":"15502925183467796581"}}},"source":["df.printSchema()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- x: integer (nullable = true)\n"," |-- age: integer (nullable = true)\n"," |-- workclass: string (nullable = true)\n"," |-- fnlwgt: integer (nullable = true)\n"," |-- education: string (nullable = true)\n"," |-- educational-num: integer (nullable = true)\n"," |-- marital-status: string (nullable = true)\n"," |-- occupation: string (nullable = true)\n"," |-- relationship: string (nullable = true)\n"," |-- race: string (nullable = true)\n"," |-- gender: string (nullable = true)\n"," |-- capital-gain: integer (nullable = true)\n"," |-- capital-loss: integer (nullable = true)\n"," |-- hours-per-week: integer (nullable = true)\n"," |-- native-country: string (nullable = true)\n"," |-- income: string (nullable = true)\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53C-0DeBFwNF","outputId":"2567a18e-953d-45ab-9ed7-ff6dcd06dcde","executionInfo":{"status":"ok","timestamp":1669224534197,"user_tz":480,"elapsed":1218,"user":{"displayName":"Yu Zhang","userId":"11411762061517189708"}}},"source":["df.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n","|  x|age|       workclass|fnlwgt|   education|educational-num|    marital-status|       occupation| relationship|              race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n","+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n","|  1| 25|         Private|226802|        11th|              7|     Never-married|Machine-op-inspct|    Own-child|             Black|  Male|           0|           0|            40| United-States| <=50K|\n","|  2| 38|         Private| 89814|     HS-grad|              9|Married-civ-spouse|  Farming-fishing|      Husband|             White|  Male|           0|           0|            50| United-States| <=50K|\n","|  3| 28|       Local-gov|336951|  Assoc-acdm|             12|Married-civ-spouse|  Protective-serv|      Husband|             White|  Male|           0|           0|            40| United-States|  >50K|\n","|  4| 44|         Private|160323|Some-college|             10|Married-civ-spouse|Machine-op-inspct|      Husband|             Black|  Male|        7688|           0|            40| United-States|  >50K|\n","|  5| 18|               ?|103497|Some-college|             10|     Never-married|                ?|    Own-child|             White|Female|           0|           0|            30| United-States| <=50K|\n","|  6| 34|         Private|198693|        10th|              6|     Never-married|    Other-service|Not-in-family|             White|  Male|           0|           0|            30| United-States| <=50K|\n","|  7| 29|               ?|227026|     HS-grad|              9|     Never-married|                ?|    Unmarried|             Black|  Male|           0|           0|            40| United-States| <=50K|\n","|  8| 63|Self-emp-not-inc|104626| Prof-school|             15|Married-civ-spouse|   Prof-specialty|      Husband|             White|  Male|        3103|           0|            32| United-States|  >50K|\n","|  9| 24|         Private|369667|Some-college|             10|     Never-married|    Other-service|    Unmarried|             White|Female|           0|           0|            40| United-States| <=50K|\n","| 10| 55|         Private|104996|     7th-8th|              4|Married-civ-spouse|     Craft-repair|      Husband|             White|  Male|           0|           0|            10| United-States| <=50K|\n","| 11| 65|         Private|184454|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|        6418|           0|            40| United-States|  >50K|\n","| 12| 36|     Federal-gov|212465|   Bachelors|             13|Married-civ-spouse|     Adm-clerical|      Husband|             White|  Male|           0|           0|            40| United-States| <=50K|\n","| 13| 26|         Private| 82091|     HS-grad|              9|     Never-married|     Adm-clerical|Not-in-family|             White|Female|           0|           0|            39| United-States| <=50K|\n","| 14| 58|               ?|299831|     HS-grad|              9|Married-civ-spouse|                ?|      Husband|             White|  Male|           0|           0|            35| United-States| <=50K|\n","| 15| 48|         Private|279724|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|        3103|           0|            48| United-States|  >50K|\n","| 16| 43|         Private|346189|     Masters|             14|Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            50| United-States|  >50K|\n","| 17| 20|       State-gov|444554|Some-college|             10|     Never-married|    Other-service|    Own-child|             White|  Male|           0|           0|            25| United-States| <=50K|\n","| 18| 43|         Private|128354|     HS-grad|              9|Married-civ-spouse|     Adm-clerical|         Wife|             White|Female|           0|           0|            30| United-States| <=50K|\n","| 19| 37|         Private| 60548|     HS-grad|              9|           Widowed|Machine-op-inspct|    Unmarried|             White|Female|           0|           0|            20| United-States| <=50K|\n","| 20| 40|         Private| 85019|   Doctorate|             16|Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|           0|           0|            45|             ?|  >50K|\n","+---+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"w7Ab64IKEZMV"},"source":["**Step 5**: Function that converts the data types of the DataFrame columns"]},{"cell_type":"code","metadata":{"id":"9_G9ddxbFO_e"},"source":["# Write a custom function to convert the data type of DataFrame columns\n","def convertColumn(df, names, newType):\n","  for name in names: \n","     df = df.withColumn(name, df[name].cast(newType))\n","  return df "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3oitXZU-InTM"},"source":["# Assign all column names to `columns`\n","columns = ['age', 'fnlwgt','capital-gain', 'educational-num', 'capital-loss', 'hours-per-week']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SmOD6XyWFTxZ"},"source":["**Step 6**: Convert the data types of the above mentioned columns into a float type"]},{"cell_type":"code","metadata":{"id":"PnAjqyaVI9KV"},"source":["from pyspark.sql.types import *\n","# Conver the `df` columns to `FloatType()`\n","df = convertColumn(df, columns, FloatType())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TEVrtaQjJbRK"},"source":["**Step 7**: Confirm that the data type has been converted into float"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cw5LNnmuJaMc","outputId":"2f49cbc9-8c02-4b68-a807-ef42f3614ba0","executionInfo":{"status":"ok","timestamp":1679059398475,"user_tz":420,"elapsed":6,"user":{"displayName":"Yu Zhang","userId":"15502925183467796581"}}},"source":["df.dtypes"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('x', 'int'),\n"," ('age', 'float'),\n"," ('workclass', 'string'),\n"," ('fnlwgt', 'float'),\n"," ('education', 'string'),\n"," ('educational-num', 'float'),\n"," ('marital-status', 'string'),\n"," ('occupation', 'string'),\n"," ('relationship', 'string'),\n"," ('race', 'string'),\n"," ('gender', 'string'),\n"," ('capital-gain', 'float'),\n"," ('capital-loss', 'float'),\n"," ('hours-per-week', 'float'),\n"," ('native-country', 'string'),\n"," ('income', 'string')]"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"IKGhjGYgKJtM"},"source":["**Step 8**: Drop rows that have a '?' in them\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zxyed8t_PzmQ","outputId":"075dfcd4-7165-439b-d7b8-ecfc57cf2553","executionInfo":{"status":"ok","timestamp":1679059400012,"user_tz":420,"elapsed":1541,"user":{"displayName":"Yu Zhang","userId":"15502925183467796581"}}},"source":["import numpy as np \n","df = df.replace(\"?\", \"np.Nan\")\n","\n","# Remove missing value\n","df = df.filter(\"workclass != 'np.Nan'\").filter(\"occupation != 'np.Nan'\").filter(\"`native-country` != 'np.Nan'\")\n","df.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+----+----------------+--------+------------+---------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n","|  x| age|       workclass|  fnlwgt|   education|educational-num|    marital-status|       occupation| relationship| race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n","+---+----+----------------+--------+------------+---------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n","|  1|25.0|         Private|226802.0|        11th|            7.0|     Never-married|Machine-op-inspct|    Own-child|Black|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n","|  2|38.0|         Private| 89814.0|     HS-grad|            9.0|Married-civ-spouse|  Farming-fishing|      Husband|White|  Male|         0.0|         0.0|          50.0| United-States| <=50K|\n","|  3|28.0|       Local-gov|336951.0|  Assoc-acdm|           12.0|Married-civ-spouse|  Protective-serv|      Husband|White|  Male|         0.0|         0.0|          40.0| United-States|  >50K|\n","|  4|44.0|         Private|160323.0|Some-college|           10.0|Married-civ-spouse|Machine-op-inspct|      Husband|Black|  Male|      7688.0|         0.0|          40.0| United-States|  >50K|\n","|  6|34.0|         Private|198693.0|        10th|            6.0|     Never-married|    Other-service|Not-in-family|White|  Male|         0.0|         0.0|          30.0| United-States| <=50K|\n","|  8|63.0|Self-emp-not-inc|104626.0| Prof-school|           15.0|Married-civ-spouse|   Prof-specialty|      Husband|White|  Male|      3103.0|         0.0|          32.0| United-States|  >50K|\n","|  9|24.0|         Private|369667.0|Some-college|           10.0|     Never-married|    Other-service|    Unmarried|White|Female|         0.0|         0.0|          40.0| United-States| <=50K|\n","| 10|55.0|         Private|104996.0|     7th-8th|            4.0|Married-civ-spouse|     Craft-repair|      Husband|White|  Male|         0.0|         0.0|          10.0| United-States| <=50K|\n","| 11|65.0|         Private|184454.0|     HS-grad|            9.0|Married-civ-spouse|Machine-op-inspct|      Husband|White|  Male|      6418.0|         0.0|          40.0| United-States|  >50K|\n","| 12|36.0|     Federal-gov|212465.0|   Bachelors|           13.0|Married-civ-spouse|     Adm-clerical|      Husband|White|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n","| 13|26.0|         Private| 82091.0|     HS-grad|            9.0|     Never-married|     Adm-clerical|Not-in-family|White|Female|         0.0|         0.0|          39.0| United-States| <=50K|\n","| 15|48.0|         Private|279724.0|     HS-grad|            9.0|Married-civ-spouse|Machine-op-inspct|      Husband|White|  Male|      3103.0|         0.0|          48.0| United-States|  >50K|\n","| 16|43.0|         Private|346189.0|     Masters|           14.0|Married-civ-spouse|  Exec-managerial|      Husband|White|  Male|         0.0|         0.0|          50.0| United-States|  >50K|\n","| 17|20.0|       State-gov|444554.0|Some-college|           10.0|     Never-married|    Other-service|    Own-child|White|  Male|         0.0|         0.0|          25.0| United-States| <=50K|\n","| 18|43.0|         Private|128354.0|     HS-grad|            9.0|Married-civ-spouse|     Adm-clerical|         Wife|White|Female|         0.0|         0.0|          30.0| United-States| <=50K|\n","| 19|37.0|         Private| 60548.0|     HS-grad|            9.0|           Widowed|Machine-op-inspct|    Unmarried|White|Female|         0.0|         0.0|          20.0| United-States| <=50K|\n","| 21|34.0|         Private|107914.0|   Bachelors|           13.0|Married-civ-spouse|     Tech-support|      Husband|White|  Male|         0.0|         0.0|          47.0| United-States|  >50K|\n","| 22|34.0|         Private|238588.0|Some-college|           10.0|     Never-married|    Other-service|    Own-child|Black|Female|         0.0|         0.0|          35.0| United-States| <=50K|\n","| 24|25.0|         Private|220931.0|   Bachelors|           13.0|     Never-married|   Prof-specialty|Not-in-family|White|  Male|         0.0|         0.0|          43.0|          Peru| <=50K|\n","| 25|25.0|         Private|205947.0|   Bachelors|           13.0|Married-civ-spouse|   Prof-specialty|      Husband|White|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n","+---+----+----------------+--------+------------+---------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"V5qQU4iXb0TH"},"source":["**Step 9:** Use \"StringIndexer\" and \"OneHotEncoding\" to convert categorical features into numeric values"]},{"cell_type":"code","metadata":{"id":"q8BHxHfpbyfg"},"source":["from pyspark.ml.feature import StringIndexer\n","from pyspark.ml.feature import OneHotEncoder\n","from pyspark.ml.feature import VectorAssembler\n","\n","#Store all the categorical columns\n","categorical_Cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n","pipeline_stages = []\n","\n","#Iterate throughthe categorical columns\n","for categoricalCol in categorical_Cols :\n","    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + '_Index')\n","    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"_conv\"])\n","    pipeline_stages += [stringIndexer, encoder]\n","\n","label_stringIdx = StringIndexer(inputCol = 'income', outputCol = 'label')\n","#Add another stage to the ML pipeline\n","pipeline_stages += [label_stringIdx]\n","\n","#Store all the numeric columns\n","numericCols = ['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n","assembler_Inputs = [c + \"_conv\" for c in categorical_Cols] + numericCols\n","assembler = VectorAssembler(inputCols=assembler_Inputs, outputCol=\"features\")\n","pipeline_stages += [assembler]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M0tA6Gn-dhgu"},"source":["**Step 10**: We use the ML Pipeline to chain multiple Transformers and Estimators together to screate the machine learning workflow."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pnKETKICdpsH","outputId":"5f5e43cb-b0ae-44f5-f693-958605c054ba","executionInfo":{"status":"ok","timestamp":1679059413034,"user_tz":420,"elapsed":12621,"user":{"displayName":"Yu Zhang","userId":"15502925183467796581"}}},"source":["from pyspark.ml import Pipeline\n","\n","ml_pipe = Pipeline(stages = pipeline_stages)\n","# Fit and transform the data\n","pipe_data = ml_pipe.fit(df).transform(df)\n","selectedCols = ['label', 'features'] + df.columns\n","df = pipe_data.select(selectedCols)\n","df.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+--------------------+---+----+----------------+--------+------------+---------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n","|label|            features|  x| age|       workclass|  fnlwgt|   education|educational-num|    marital-status|       occupation| relationship| race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n","+-----+--------------------+---+----+----------------+--------+------------+---------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n","|  0.0|(95,[0,11,22,33,4...|  1|25.0|         Private|226802.0|        11th|            7.0|     Never-married|Machine-op-inspct|    Own-child|Black|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n","|  0.0|(95,[0,6,21,36,40...|  2|38.0|         Private| 89814.0|     HS-grad|            9.0|Married-civ-spouse|  Farming-fishing|      Husband|White|  Male|         0.0|         0.0|          50.0| United-States| <=50K|\n","|  1.0|(95,[2,12,21,38,4...|  3|28.0|       Local-gov|336951.0|  Assoc-acdm|           12.0|Married-civ-spouse|  Protective-serv|      Husband|White|  Male|         0.0|         0.0|          40.0| United-States|  >50K|\n","|  1.0|(95,[0,7,21,33,40...|  4|44.0|         Private|160323.0|Some-college|           10.0|Married-civ-spouse|Machine-op-inspct|      Husband|Black|  Male|      7688.0|         0.0|          40.0| United-States|  >50K|\n","|  0.0|(95,[0,13,22,32,4...|  6|34.0|         Private|198693.0|        10th|            6.0|     Never-married|    Other-service|Not-in-family|White|  Male|         0.0|         0.0|          30.0| United-States| <=50K|\n","|  1.0|(95,[1,15,21,28,4...|  8|63.0|Self-emp-not-inc|104626.0| Prof-school|           15.0|Married-civ-spouse|   Prof-specialty|      Husband|White|  Male|      3103.0|         0.0|          32.0| United-States|  >50K|\n","|  0.0|(95,[0,7,22,32,43...|  9|24.0|         Private|369667.0|Some-college|           10.0|     Never-married|    Other-service|    Unmarried|White|Female|         0.0|         0.0|          40.0| United-States| <=50K|\n","|  0.0|(95,[0,14,21,27,4...| 10|55.0|         Private|104996.0|     7th-8th|            4.0|Married-civ-spouse|     Craft-repair|      Husband|White|  Male|         0.0|         0.0|          10.0| United-States| <=50K|\n","|  1.0|(95,[0,6,21,33,40...| 11|65.0|         Private|184454.0|     HS-grad|            9.0|Married-civ-spouse|Machine-op-inspct|      Husband|White|  Male|      6418.0|         0.0|          40.0| United-States|  >50K|\n","|  0.0|(95,[5,8,21,30,40...| 12|36.0|     Federal-gov|212465.0|   Bachelors|           13.0|Married-civ-spouse|     Adm-clerical|      Husband|White|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n","|  0.0|(95,[0,6,22,30,41...| 13|26.0|         Private| 82091.0|     HS-grad|            9.0|     Never-married|     Adm-clerical|Not-in-family|White|Female|         0.0|         0.0|          39.0| United-States| <=50K|\n","|  1.0|(95,[0,6,21,33,40...| 15|48.0|         Private|279724.0|     HS-grad|            9.0|Married-civ-spouse|Machine-op-inspct|      Husband|White|  Male|      3103.0|         0.0|          48.0| United-States|  >50K|\n","|  1.0|(95,[0,9,21,29,40...| 16|43.0|         Private|346189.0|     Masters|           14.0|Married-civ-spouse|  Exec-managerial|      Husband|White|  Male|         0.0|         0.0|          50.0| United-States|  >50K|\n","|  0.0|(95,[3,7,22,32,42...| 17|20.0|       State-gov|444554.0|Some-college|           10.0|     Never-married|    Other-service|    Own-child|White|  Male|         0.0|         0.0|          25.0| United-States| <=50K|\n","|  0.0|(95,[0,6,21,30,44...| 18|43.0|         Private|128354.0|     HS-grad|            9.0|Married-civ-spouse|     Adm-clerical|         Wife|White|Female|         0.0|         0.0|          30.0| United-States| <=50K|\n","|  0.0|(95,[0,6,25,33,43...| 19|37.0|         Private| 60548.0|     HS-grad|            9.0|           Widowed|Machine-op-inspct|    Unmarried|White|Female|         0.0|         0.0|          20.0| United-States| <=50K|\n","|  1.0|(95,[0,8,21,37,40...| 21|34.0|         Private|107914.0|   Bachelors|           13.0|Married-civ-spouse|     Tech-support|      Husband|White|  Male|         0.0|         0.0|          47.0| United-States|  >50K|\n","|  0.0|(95,[0,7,22,32,42...| 22|34.0|         Private|238588.0|Some-college|           10.0|     Never-married|    Other-service|    Own-child|Black|Female|         0.0|         0.0|          35.0| United-States| <=50K|\n","|  0.0|(95,[0,8,22,28,41...| 24|25.0|         Private|220931.0|   Bachelors|           13.0|     Never-married|   Prof-specialty|Not-in-family|White|  Male|         0.0|         0.0|          43.0|          Peru| <=50K|\n","|  0.0|(95,[0,8,21,28,40...| 25|25.0|         Private|205947.0|   Bachelors|           13.0|Married-civ-spouse|   Prof-specialty|      Husband|White|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n","+-----+--------------------+---+----+----------------+--------+------------+---------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"QYcUtzrZd4kl"},"source":["**Step 11:** Split the data set into Train and Test data sets respectively"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CpO22QnueBt1","outputId":"556a5e14-e64f-4be9-a536-7c57b48f0a8c","executionInfo":{"status":"ok","timestamp":1679059419802,"user_tz":420,"elapsed":6782,"user":{"displayName":"Yu Zhang","userId":"15502925183467796581"}}},"source":["train, test = df.randomSplit([0.7, 0.3], seed = 12345)\n","print(\"Training Dataset Count: \" + str(train.count()))\n","print(\"Test Dataset Count: \" + str(test.count()))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Dataset Count: 31545\n","Test Dataset Count: 13677\n"]}]},{"cell_type":"markdown","metadata":{"id":"LA_uDEIIeV7S"},"source":["**Step 12**: Create a Logistic Regression Model"]},{"cell_type":"code","metadata":{"id":"l6QKdj9zeRwF"},"source":["# Import `LogisticRegression`\n","from pyspark.ml.classification import LogisticRegression\n","\n","# Initialize `lr`\n","lr = LogisticRegression(labelCol=\"label\",\n","                        featuresCol=\"features\",\n","                        maxIter=10,\n","                        regParam=0.3)\n","\n","# Fit the data to the model\n","linearModel = lr.fit(train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"coNnDdb-etHf"},"source":["**Step 13**: Make predictions on test data using the transform() method.\n"]},{"cell_type":"code","metadata":{"id":"SA2MTCXUezpy"},"source":["predictions = linearModel.transform(test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L2v-eOmjfKuu"},"source":["**Step 14**: Examine the elements in predictions object"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vXRVKBiMfXHy","outputId":"33a5b672-1bf3-4a7f-ab7e-7c2f200d9ee9","executionInfo":{"status":"ok","timestamp":1679059427680,"user_tz":420,"elapsed":15,"user":{"displayName":"Yu Zhang","userId":"15502925183467796581"}}},"source":["predictions.printSchema()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- label: double (nullable = false)\n"," |-- features: vector (nullable = true)\n"," |-- x: integer (nullable = true)\n"," |-- age: float (nullable = true)\n"," |-- workclass: string (nullable = true)\n"," |-- fnlwgt: float (nullable = true)\n"," |-- education: string (nullable = true)\n"," |-- educational-num: float (nullable = true)\n"," |-- marital-status: string (nullable = true)\n"," |-- occupation: string (nullable = true)\n"," |-- relationship: string (nullable = true)\n"," |-- race: string (nullable = true)\n"," |-- gender: string (nullable = true)\n"," |-- capital-gain: float (nullable = true)\n"," |-- capital-loss: float (nullable = true)\n"," |-- hours-per-week: float (nullable = true)\n"," |-- native-country: string (nullable = true)\n"," |-- income: string (nullable = true)\n"," |-- rawPrediction: vector (nullable = true)\n"," |-- probability: vector (nullable = true)\n"," |-- prediction: double (nullable = false)\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"J9fDEeEjfkiC"},"source":["**Step 15**: Investigate the predictions"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1FqMbqifq1a","outputId":"1e47ed9a-c810-42fb-9225-61cf5d37a93f","executionInfo":{"status":"ok","timestamp":1679059429542,"user_tz":420,"elapsed":1876,"user":{"displayName":"Yu Zhang","userId":"15502925183467796581"}}},"source":["predictions.select( 'label', 'rawPrediction', 'prediction', 'probability').show(50)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+--------------------+----------+--------------------+\n","|label|       rawPrediction|prediction|         probability|\n","+-----+--------------------+----------+--------------------+\n","|  0.0|[0.79876961965233...|       0.0|[0.68971122934134...|\n","|  0.0|[0.78132835086031...|       0.0|[0.68596633332400...|\n","|  0.0|[0.53451133331672...|       0.0|[0.63053469278484...|\n","|  0.0|[0.69231624365181...|       0.0|[0.66648198845505...|\n","|  0.0|[0.72132307261904...|       0.0|[0.67289830011546...|\n","|  0.0|[0.63428066917326...|       0.0|[0.65345945627976...|\n","|  0.0|[0.57080622929525...|       0.0|[0.63894918753099...|\n","|  0.0|[0.39482989245959...|       0.0|[0.59744485487626...|\n","|  0.0|[0.22808136455443...|       0.0|[0.55677443185898...|\n","|  0.0|[0.93474652562327...|       0.0|[0.71803725965986...|\n","|  0.0|[0.97446125361469...|       0.0|[0.72600782663058...|\n","|  0.0|[0.89798700544308...|       0.0|[0.71053565602872...|\n","|  0.0|[0.91481637049542...|       0.0|[0.71398472917133...|\n","|  0.0|[0.90222304752348...|       0.0|[0.71140612525273...|\n","|  0.0|[0.90673692777695...|       0.0|[0.71233197342441...|\n","|  0.0|[0.92236146442056...|       0.0|[0.71552302591208...|\n","|  0.0|[0.92009641045569...|       0.0|[0.71506174958859...|\n","|  0.0|[0.88935068312505...|       0.0|[0.70875615818442...|\n","|  0.0|[0.89425836479438...|       0.0|[0.70976816724334...|\n","|  0.0|[0.84534163182821...|       0.0|[0.69958903134394...|\n","|  0.0|[0.89851010873845...|       0.0|[0.71064323331156...|\n","|  0.0|[0.91208620169951...|       0.0|[0.71342687437871...|\n","|  0.0|[0.87967615836257...|       0.0|[0.70675510865542...|\n","|  0.0|[0.68868533538068...|       0.0|[0.66567440927873...|\n","|  0.0|[0.88452471713678...|       0.0|[0.70775897542728...|\n","|  0.0|[0.88718902065480...|       0.0|[0.70830974466951...|\n","|  0.0|[0.88866761209903...|       0.0|[0.70861513796807...|\n","|  0.0|[0.88895164659809...|       0.0|[0.70867378185782...|\n","|  0.0|[0.92280149580968...|       0.0|[0.71561258572944...|\n","|  0.0|[0.90288495823602...|       0.0|[0.71154200143500...|\n","|  0.0|[0.85346408533767...|       0.0|[0.70129330817588...|\n","|  0.0|[0.74945478239987...|       0.0|[0.67905988738587...|\n","|  0.0|[0.87956865529341...|       0.0|[0.70673282789918...|\n","|  0.0|[0.85023810738550...|       0.0|[0.70061708854653...|\n","|  0.0|[0.89221739202087...|       0.0|[0.70934755239765...|\n","|  0.0|[0.86488886995786...|       0.0|[0.70368106635210...|\n","|  0.0|[0.87192853163061...|       0.0|[0.70514682680186...|\n","|  0.0|[0.87334684955609...|       0.0|[0.70544163023409...|\n","|  0.0|[0.87515155996810...|       0.0|[0.70581649866507...|\n","|  0.0|[0.87669192285286...|       0.0|[0.70613623751968...|\n","|  0.0|[0.81344119473987...|       0.0|[0.69284231686612...|\n","|  0.0|[0.88199456591160...|       0.0|[0.70723537358380...|\n","|  0.0|[0.89441105343540...|       0.0|[0.70979961968612...|\n","|  0.0|[0.90330100513967...|       0.0|[0.71162738753815...|\n","|  0.0|[0.86487323942381...|       0.0|[0.70367780715618...|\n","|  0.0|[0.87265422971250...|       0.0|[0.70529768769252...|\n","|  0.0|[0.83458925176018...|       0.0|[0.69732442763852...|\n","|  0.0|[0.80975822374010...|       0.0|[0.69205798085348...|\n","|  0.0|[0.87420757458592...|       0.0|[0.70562045187235...|\n","|  0.0|[0.88081661941518...|       0.0|[0.70699141611420...|\n","+-----+--------------------+----------+--------------------+\n","only showing top 50 rows\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"AmVLs3yNf15r"},"source":["**Step 16**: Evaluate the predictions\n","\n","**Evaluating the Model** - Since the Logistic model at hand is a binary classification model (given that the outcome is 1 or 0), the BinaryClassificationEvaluator from the ***pyspark.ml.evaluation*** module will be utilized to evaluate the Logistic Regression Model.\n","\n","The BinaryClassificationEvaluator calculates the area under the ROC which is is one of the most important evaluation metrics for checking any classification model’s performance. It finds the best model by maximizing the model evaluation metric that is the area under the specified curve. The closer the area Under Curve is to one (1), the better the model is!\n","\n","For more details, check out: https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6Quw7Ssf8CS","outputId":"0aba6ac5-5541-410e-d104-f790142ca0d9","executionInfo":{"status":"ok","timestamp":1668206514309,"user_tz":480,"elapsed":4170,"user":{"displayName":"Yu Zhang","userId":"11411762061517189708"}}},"source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","\n","evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol=\"label\",metricName=\"areaUnderROC\")\n","\n","# Evaluate the predictions\n","print(\"The area under ROC for test data set is {}\".format(evaluator.evaluate(predictions)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The area under ROC for test data set is 0.8843278752871817\n"]}]},{"cell_type":"code","source":["#Add Majed\n","!pip install handyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QWjzNhtP_mS1","outputId":"a1e0b022-1626-48d7-a2f8-48057e302f59","executionInfo":{"status":"ok","timestamp":1668206519485,"user_tz":480,"elapsed":4350,"user":{"displayName":"Yu Zhang","userId":"11411762061517189708"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting handyspark\n","  Downloading handyspark-0.2.2a1-py2.py3-none-any.whl (39 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from handyspark) (1.21.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from handyspark) (1.0.2)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from handyspark) (6.0.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from handyspark) (0.11.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from handyspark) (1.7.3)\n","Requirement already satisfied: findspark in /usr/local/lib/python3.7/dist-packages (from handyspark) (2.0.1)\n","Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (from handyspark) (3.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from handyspark) (1.3.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from handyspark) (3.2.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->handyspark) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->handyspark) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->handyspark) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->handyspark) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->handyspark) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->handyspark) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->handyspark) (2022.6)\n","Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark->handyspark) (0.10.9)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->handyspark) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->handyspark) (3.1.0)\n","Installing collected packages: handyspark\n","Successfully installed handyspark-0.2.2a1\n"]}]},{"cell_type":"code","source":["import handyspark\n","bcm = handyspark.BinaryClassificationMetrics(predictions, scoreCol='probability', labelCol='label')\n","\n","import matplotlib.pyplot as plt\n","fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n","bcm.plot_roc_curve(ax=axs[0])\n","bcm.plot_pr_curve(ax=axs[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"0P9ZS4F9-0Jw","outputId":"11f3ed8d-e6d2-4a85-e4c8-a38b6d541931","executionInfo":{"status":"error","timestamp":1679059457563,"user_tz":420,"elapsed":138,"user":{"displayName":"Yu Zhang","userId":"15502925183467796581"}}},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-a1649b05c31a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhandyspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryClassificationMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoreCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'probability'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'handyspark'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}]}